{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "ORIGINAL_DB = Path(\"./psb_orig.csv\")\n",
    "PROCESSED_DB = Path(\"./psb_proc.csv\")\n",
    "\n",
    "df_orig = pd.read_csv(ORIGINAL_DB)\n",
    "df_proc = pd.read_csv(PROCESSED_DB)\n",
    "\n",
    "ORIGINAL_MODEL_DIR = Path(\"./models\")\n",
    "PROCESSED_MODEL_DIR = Path(\"./processed-models\")\n",
    "\n",
    "# List string to numpy array\n",
    "for col in [\"Bounding box\", \"Barycenter\", \"A3\", \"D1\", \"D2\", \"D3\", \"D4\"]:\n",
    "    df_orig[col] = df_orig[col].str.replace(\"nan\", \"0\")\n",
    "    df_proc[col] = df_proc[col].str.replace(\"nan\", \"0\")\n",
    "\n",
    "    df_orig[col] = df_orig[col].apply(eval).apply(np.array)\n",
    "    df_proc[col] = df_proc[col].apply(eval).apply(np.array)\n",
    "\n",
    "df_orig[\"Max bound\"] = df_orig[\"Bounding box\"].apply(lambda x: max(np.abs(x[0] - x[1])))\n",
    "df_proc[\"Max bound\"] = df_proc[\"Bounding box\"].apply(lambda x: max(np.abs(x[0] - x[1])))\n",
    "\n",
    "df_orig[\"Distance from origin\"] = df_orig[\"Barycenter\"].apply(np.linalg.norm)\n",
    "df_proc[\"Distance from origin\"] = df_proc[\"Barycenter\"].apply(np.linalg.norm)\n",
    "\n",
    "df_proc[\"Diameter\"].describe()\n",
    "\n",
    "df_proc.replace(np.inf, np.finfo(np.float64).max, inplace=True)\n",
    "df_proc.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "# Calculate the feature vector for every entry in the dataset\n",
    "df_proc[\"Feature Vector\"] = df_proc.apply(lambda x: np.array([x[\"Surface\"], x[\"Compactness\"], x[\"Bounding box volume\"], x[\"Diameter\"], x[\"Eccentricity\"], *x[\"A3\"], *x[\"D1\"], *x[\"D2\"], *x[\"D3\"], *x[\"D4\"]]), axis=1)\n",
    "\n",
    "# Probably normalize this feature vector here\n",
    "# TODO: Normalize feature vector either by min..max normalization or standardization\n",
    "# TODO: Weigh feature somehow\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = list(df_proc[\"Feature Vector\"].map(list))\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "df_proc[\"Feature Vector\"] = df_proc[\"Feature Vector\"].apply(lambda x: scaler.transform(x.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object import Object\n",
    "from viewer import Viewer\n",
    "\n",
    "# Select the number of the model to query here\n",
    "NO_TO_QUERY = 1\n",
    "\n",
    "obj = Object.load_mesh(list(PROCESSED_MODEL_DIR.glob(f\"**/m{NO_TO_QUERY}.off\"))[0])\n",
    "\n",
    "view_object = False\n",
    "\n",
    "if view_object:\n",
    "    viewer = Viewer(obj)\n",
    "    viewer.mainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature vector from the selected model\n",
    "# Recalculate it so we can also pick models from outside of our dataset\n",
    "model_num, label, num_vertices, num_faces, num_edges, type_faces, bounding_box, barycenter, diagonal, surface, bounding_box_volume, volume, compactness, diameter, eccentricity, A3, D1, D2, D3, D4= obj.get_info()\n",
    "\n",
    "feature_vector = np.array([surface, compactness, bounding_box_volume, diameter, eccentricity, *A3, *D1, *D2, *D3, *D4])\n",
    "\n",
    "feature_vector = scaler.transform([feature_vector])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance of each object in the shapebase to the feature vector using a euclidean distance metric\n",
    "df_proc[\"Distance\"] = df_proc.apply(lambda x: np.linalg.norm(x[\"Feature Vector\"] - feature_vector), axis=1)\n",
    "\n",
    "# Take the smallest n distances and display their features\n",
    "df_proc.nsmallest(5, \"Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "match_counts = []\n",
    "matches = []\n",
    "\n",
    "for i, row in df_proc.iterrows():\n",
    "    vec = row[\"Feature Vector\"]\n",
    "    label = row[\"Label\"]\n",
    "    model_num = row[\"Model number\"]\n",
    "\n",
    "    df_proc[\"Distance\"] = df_proc.apply(lambda x: np.linalg.norm(x[\"Feature Vector\"] - vec), axis=1)\n",
    "\n",
    "    top_k = df_proc.nsmallest(k + 1, \"Distance\")\n",
    "    top_k = top_k[top_k[\"Model number\"] != model_num]\n",
    "\n",
    "    match_count = len(top_k[top_k[\"Label\"] == label])\n",
    "\n",
    "    match = max(set(top_k[\"Label\"]), key = list(top_k[\"Label\"]).count) == label\n",
    "\n",
    "    matches.append(match)\n",
    "\n",
    "    match_counts.append(match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count: \", len(match_counts))\n",
    "print(\"Max: \", max(match_counts))\n",
    "print(\"Min: \", min(match_counts))\n",
    "print(\"Avg: \", sum(match_counts) / len(match_counts))\n",
    "print(\"Correct matches: \", sum(matches))\n",
    "print(f\"Correct matches: {sum(matches) / len(match_counts) * 100: .2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a054dfacaac4c7c14f0d4b240b81f51a53685958321ddcc9146e07156cae54cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
